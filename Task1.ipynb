{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom dataset class to output input and corresponding labels\n",
    "class dataset(Dataset):\n",
    "  def __init__(self,path):\n",
    "    self.path=path\n",
    "    h5_file=h5py.File(path,'r')\n",
    "    self.input=h5_file[\"X\"]\n",
    "    self.label=h5_file[\"y\"]\n",
    "  def __len__(self):\n",
    "    self.filelength=self.input.shape[0]\n",
    "    return self.filelength \n",
    "  \n",
    "  def __getitem__(self,idx):\n",
    "    # input1=torch.reshape(torch.from_numpy(self.input[idx][:,:,0]),(1,32,32))\n",
    "    # input2=torch.reshape(torch.from_numpy(self.input[idx][:,:,1]),(32,32))\n",
    "    \n",
    "    input_stack=torch.stack([torch.from_numpy(self.input[idx][:,:,0]),torch.from_numpy(self.input[idx][:,:,1])],dim=0)\n",
    "\n",
    "\n",
    "    \n",
    "    return input_stack,self.label[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset split\n",
    "data_electron=dataset(\"/home/g0kul6/g0kul6/ml4sci/DATA/Data_Task1/SingleElectronPt50_IMGCROPS_n249k_RHv1.hdf5\")\n",
    "data_photon=dataset(\"/home/g0kul6/g0kul6/ml4sci/DATA/Data_Task1/SinglePhotonPt50_IMGCROPS_n249k_RHv1.hdf5\")\n",
    "data=data_photon+data_electron\n",
    "train_data,test_data=random_split(data,[len(data)-int(0.18*len(data)),int(0.18*len(data))],generator=torch.Generator().manual_seed(42))\n",
    "train_data,val_data=random_split(train_data,[len(train_data)-int(0.21875*len(train_data)),int(0.21875*len(train_data))],generator=torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319032\n"
     ]
    }
   ],
   "source": [
    "#data loader\n",
    "train_loader=DataLoader(train_data,batch_size=1,shuffle=True,num_workers=4,pin_memory=True)\n",
    "val_loader=DataLoader(val_data,batch_size=256,shuffle=True,num_workers=4,pin_memory=True)\n",
    "test_loader=DataLoader(test_data,batch_size=256,shuffle=True)\n",
    "print(len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG16(\n",
      "  (conv1_1): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv1_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2_1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3_1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv4_1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv4_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv4_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv5_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv5_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv5_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=512, out_features=85, bias=True)\n",
      "  (fc2): Linear(in_features=85, out_features=85, bias=True)\n",
      "  (fc3): Linear(in_features=85, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class VGG16(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG16, self).__init__()\n",
    "        self.conv1_1 = nn.Conv2d(in_channels=2, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv1_2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv2_1 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.conv2_2 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv3_1 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.conv3_2 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "        self.conv3_3 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv4_1 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.conv4_2 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.conv4_3 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv5_1 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.conv5_2 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "        self.conv5_3 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.fc1 = nn.Linear(512,85)\n",
    "        self.fc2 = nn.Linear(85, 85)\n",
    "        self.fc3 = nn.Linear(85, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1_1(x))\n",
    "        x = F.relu(self.conv1_2(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv2_1(x))\n",
    "        x = F.relu(self.conv2_2(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv3_1(x))\n",
    "        x = F.relu(self.conv3_2(x))\n",
    "        x = F.relu(self.conv3_3(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv4_1(x))\n",
    "        x = F.relu(self.conv4_2(x))\n",
    "        x = F.relu(self.conv4_3(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = F.relu(self.conv5_1(x))\n",
    "        x = F.relu(self.conv5_2(x))\n",
    "        x = F.relu(self.conv5_3(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, 0.5) #dropout was included to combat overfitting\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.dropout(x, 0.5)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net=VGG16()\n",
    "net=net.train()\n",
    "net=net.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.00001)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and validation\n",
    "for epoch in range(50):\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "    \n",
    "    for data, label in train_loader:\n",
    "        \n",
    "        \n",
    "        input = data.cuda()\n",
    "        label=label.type(torch.LongTensor).cuda()\n",
    "        \n",
    "        \n",
    "        output = net(input)\n",
    "        loss = criterion(output, label)\n",
    "       \n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        acc = ((output.argmax(dim=1) == label).float().mean())\n",
    "        epoch_accuracy += acc/len(train_loader)\n",
    "        epoch_loss += loss/len(train_loader)\n",
    "    print('Epoch : {}, train accuracy : {}, train loss : {}'.format(epoch+1, epoch_accuracy,epoch_loss))\n",
    "    with torch.no_grad():\n",
    "        epoch_val_accuracy=0\n",
    "        epoch_val_loss =0\n",
    "        for data, label in val_loader:\n",
    "            data = data.cuda()\n",
    "            label=label.type(torch.LongTensor).cuda()\n",
    "            \n",
    "            val_output = net(data)\n",
    "            val_loss = criterion(val_output,label)\n",
    "            \n",
    "            \n",
    "            acc = ((val_output.argmax(dim=1) == label).float().mean())\n",
    "            epoch_val_accuracy += acc/ len(val_loader)\n",
    "            epoch_val_loss += val_loss/ len(val_loader)\n",
    "        print('Epoch : {}, val_accuracy : {}, val_loss : {}'.format(epoch+1, epoch_val_accuracy,epoch_val_loss))\n",
    "    # writer.add_scalar(\"Loss/train\", epoch_loss, epoch)\n",
    "    # writer.add_scalar(\"Loss/val\", epoch_val_loss, epoch)\n",
    "    # writer.add_scalar(\"acc/train\", epoch_accuracy, epoch)\n",
    "    # writer.add_scalar(\"acc/val\", epoch_val_accuracy, epoch)\n",
    "\n",
    "torch.save(net.state_dict(),\"task_1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6f9ebc0819e6879c9252ac39d1ed70d90cf78c6e7bbaabf45459c0f34b6327c2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
